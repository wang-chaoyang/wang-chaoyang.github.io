<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Explore In-Context Segmentation via Latent Diffusion Models">
  <meta name="keywords" content="Diffusion Model, In-context Segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Explore In-Context Segmentation via Latent Diffusion Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Explore In-Context Segmentation via Latent Diffusion Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://wang-chaoyang.github.io">Chaoyang Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://lxtgh.github.io">Xiangtai Li</a><sup>2,3</sup>,</span>
            <span class="author-block">
              <a href="https://henghuiding.github.io">Henghui Ding</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="http://luqi.info">Lu Qi</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a href="https://zhangzjn.github.io/">Jiangning Zhang</a><sup>6</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=T4gqdPkAAAAJ">Yunhai Tong</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://yanshuicheng.info">Shuicheng Yan</a><sup>2,3</sup>
            </span>            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Peking University</span>
            <span class="author-block"><sup>2</sup>Skywork AI</span>
            <span class="author-block"><sup>3</sup>Nanyang Technological University</span>
            <span class="author-block"><sup>4</sup>Fudan University</span>
            <span class="author-block"><sup>5</sup>Wuhan University</span>
            <span class="author-block"><sup>6</sup>Zhejiang University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.09616"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://wang-chaoyang.github.io/project/refldmseg/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper Teaser -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="publication-img">
            <img id="teaser" src="./static/images/teaser.png" style="width:1200px;"/>
          </div>
        </div>
      </div>
      <div style="text-align:center;"><p>
      <h2 class="subtitle">
        We propose LDIS, a minimalist LDM framework for in-context segmentation.
      </h2>
    </p></div>
    </div>
  </div>
</section>
<!-- /Paper Teaser -->


<!-- Abstract. -->
<section class="hero is-light">
  <div class="container is-max-desktop ">
    <div class="columns is-centered has-text-centered" style="margin-top: 10px; margin-bottom: 0px;">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In-context segmentation has drawn increasing attention with the advent of vision foundation models. Its goal is to segment objects using given reference images. Most existing approaches adopt metric learning or masked image modeling to build the correlation between visual prompts and input image queries. This work approaches the problem from a fresh perspective - unlocking the capability of the latent diffusion model (LDM) for in-context segmentation and investigating different design choices. Specifically, we examine the problem from three angles: instruction extraction, output alignment, and meta-architectures. We design a two-stage masking strategy to prevent interfering information from leaking into the instructions. In addition, we propose an augmented pseudo-masking target to ensure the model predicts without forgetting the original images. Moreover, we build a new and fair in-context segmentation benchmark that covers both image and video datasets. Experiments validate the effectiveness of our approach, demonstrating comparable or even stronger results than previous specialist or visual foundation models. We hope our work inspires others to rethink the unification of segmentation and generation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- /Abstract. -->

<!-- Framework. -->
<section class="section" style="margin-top:-50px; margin-bottom:-50px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3 is-centered">LDIS Framework</h2>
            <div class="publication-img">
              <img id="architecture" src="./static/images/framework.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
            </div>
          </div>
        </div>
        <p>
          LDIS operates as a minimalist and generates the mask under the guidance of in-context instructions. The two variants differ in input formulation, denoising time steps, and optimization target.
        </p>
    </div>
  </div>
</section>
<!-- /Framework  -->


<!-- Results -->
<section>
  <div class="container is-max-desktop" style="margin-top:-100px; margin-bottom:-50px;">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3 is-centered">Visual Results</h2>
        </div>
      </div>
      <img id="result-comparison" src="./static/images/seg.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
      <h2 class="subtitle has-text-centered">
        Visual results on several challenging cases.
      </h2>
    </div>
  </div>
</section>

<section>
  <div class="container is-max-desktop" style="margin-top:-50px; margin-bottom:-50px;">
    <div class="hero-body">
      <img id="result-comparison" src="./static/images/latent.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
      <h2 class="subtitle has-text-centered">
        Visualizations at different time steps.
      </h2>
    </div>
  </div>
</section>

<!-- /Results -->

<!-- BibTeX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wang2024explore,
      title={Explore In-Context Segmentation via Latent Diffusion Models},
      author={Wang, Chaoyang and Li, Xiangtai and Ding, Henghui and Qi, Lu and Zhang, Jiangning and Tong, Yunhai and Loy, Chen Change and Yan, Shuicheng},
      journal={arXiv preprint arXiv:2403.09616},
      year={2024}
    }</code></pre>
  </div>
</section>
<!-- /BibTeX -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. Thanks for their excellent work.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
